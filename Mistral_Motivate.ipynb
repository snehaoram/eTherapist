{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3d55ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fine-tuning Mistral 2 model on MotiVate dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad7b1631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5674a2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "\n",
    "anxiety = pd.read_csv('Anxiety.csv')\n",
    "depression = pd.read_csv('Depression_mod.csv')\n",
    "OCD = pd.read_csv('OCD.csv')\n",
    "PTSD = pd.read_csv('PTSD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a51cdbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4038, 2)\n",
      "(993, 2)\n",
      "(990, 2)\n",
      "(1082, 2)\n"
     ]
    }
   ],
   "source": [
    "print(depression.shape)\n",
    "print(anxiety.shape)\n",
    "print(OCD.shape)\n",
    "print(PTSD.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c14de6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7103"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4038+993+990+1082"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bfd2776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SUMMARY DIALOGUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>USER416  &gt;  Wishing for anything to take this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>USER1315  &gt;  Every day I go for a walk on natu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>USER607 &gt; ... packing for her trip, sorry does...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>USER270 &gt; So I've been severely depressed late...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>USER513  &gt;  I've been dealing with it since I ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                   SUMMARY DIALOGUE\n",
       "0   0  USER416  >  Wishing for anything to take this ...\n",
       "1   1  USER1315  >  Every day I go for a walk on natu...\n",
       "2   2  USER607 > ... packing for her trip, sorry does...\n",
       "3   3  USER270 > So I've been severely depressed late...\n",
       "4   4  USER513  >  I've been dealing with it since I ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depression.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a0ef914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "765582b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For printi\n",
    "\n",
    "def wrap(x):\n",
    "  return textwrap.fill(x, replace_whitespace=False, fix_sentence_endings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb6e33c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_anx_a = {}\n",
    "\n",
    "for i in range(0, len(anxiety)):\n",
    "    j= anxiety.iloc[i][1]\n",
    "    j = wrap(j)\n",
    "    j = j.strip()\n",
    "    j = j.replace('VA', '!')\n",
    "    reg = r'USER(\\d+)'\n",
    "    j = re.sub(reg, '!',j)\n",
    "    inner = {}\n",
    "    l = 1\n",
    "    k = 1\n",
    "    element = j.split('!')\n",
    "    while(l < len(element)-1):\n",
    "      inner[\"USER_dial\"+str(k)] = element[l]\n",
    "      inner[\"Model_dial\"+str(k)] = element[l+1]\n",
    "      out_anx_a[i] = inner\n",
    "      l = l + 2\n",
    "      k = k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3eadf601",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_anx_d = {}\n",
    "\n",
    "for i in range(0, len(depression)):\n",
    "    j= depression.iloc[i][1]\n",
    "    j = wrap(j)\n",
    "    j = j.strip()\n",
    "    j = j.replace('VA', '!')\n",
    "    reg = r'USER(\\d+)'\n",
    "    j = re.sub(reg, '!',j)\n",
    "    inner = {}\n",
    "    l = 1\n",
    "    k = 1\n",
    "    element = j.split('!')\n",
    "    while(l < len(element)-1):\n",
    "      inner[\"USER_dial\"+str(k)] = element[l]\n",
    "      inner[\"Model_dial\"+str(k)] = element[l+1]\n",
    "      out_anx_d[i] = inner\n",
    "      l = l + 2\n",
    "      k = k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "273e6a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_anx_o = {}\n",
    "\n",
    "for i in range(0, len(OCD)):\n",
    "    j= OCD.iloc[i][1]\n",
    "    j = wrap(j)\n",
    "    j = j.strip()\n",
    "    j = j.replace('VA', '!')\n",
    "    reg = r'USER(\\d+)'\n",
    "    j = re.sub(reg, '!',j)\n",
    "    inner = {}\n",
    "    l = 1\n",
    "    k = 1\n",
    "    element = j.split('!')\n",
    "    while(l < len(element)-1):\n",
    "      inner[\"USER_dial\"+str(k)] = element[l]\n",
    "      inner[\"Model_dial\"+str(k)] = element[l+1]\n",
    "      out_anx_o[i] = inner\n",
    "      l = l + 2\n",
    "      k = k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b15b1605",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_anx_p = {}\n",
    "\n",
    "for i in range(0, len(PTSD)):\n",
    "    j= PTSD.iloc[i][1]\n",
    "    j = wrap(j)\n",
    "    j = j.strip()\n",
    "    j = j.replace('VA', '!')\n",
    "    reg = r'USER(\\d+)'\n",
    "    j = re.sub(reg, '!',j)\n",
    "    inner = {}\n",
    "    l = 1\n",
    "    k = 1\n",
    "    element = j.split('!')\n",
    "    while(l < len(element)-1):\n",
    "      inner[\"USER_dial\"+str(k)] = element[l]\n",
    "      inner[\"Model_dial\"+str(k)] = element[l+1]\n",
    "      out_anx_p[i] = inner\n",
    "      l = l + 2\n",
    "      k = k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bb3a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = {i: v for i, v in enumerate(out_anx_a.values())}\n",
    "out_anx_a = d1\n",
    "\n",
    "d2 = {i: v for i, v in enumerate(out_anx_d.values())}\n",
    "out_anx_d = d2\n",
    "\n",
    "d3 = {i: v for i, v in enumerate(out_anx_o.values())}\n",
    "out_anx_o = d3\n",
    "\n",
    "d4 = {i: v for i, v in enumerate(out_anx_p.values())}\n",
    "out_anx_p = d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fbbd699",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_a = out_anx_a\n",
    "new_d = out_anx_d\n",
    "new_o = out_anx_o\n",
    "new_p = out_anx_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60713ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in new_a:\n",
    "  k = new_a[i]\n",
    "  for j in range(1, int(len(k)/2)+1):\n",
    "    d = new_a[i]['USER_dial'+str(j)].strip()\n",
    "    d = d.replace(\">\", \"\").replace(\"\\n\", \" \")\n",
    "    new_a[i]['USER_dial'+str(j)] = d\n",
    "\n",
    "\n",
    "for i in new_d:\n",
    "  k = new_d[i]\n",
    "  for j in range(1, int(len(k)/2)+1):\n",
    "    d = new_d[i]['USER_dial'+str(j)].strip()\n",
    "    d = d.replace(\">\", \"\").replace(\"\\n\", \" \")\n",
    "    new_d[i]['USER_dial'+str(j)] = d\n",
    "\n",
    "\n",
    "for i in new_o:\n",
    "  k = new_o[i]\n",
    "  for j in range(1, int(len(k)/2)+1):\n",
    "    d = new_o[i]['USER_dial'+str(j)].strip()\n",
    "    d = d.replace(\">\", \"\").replace(\"\\n\", \" \")\n",
    "    new_o[i]['USER_dial'+str(j)] = d\n",
    "\n",
    "\n",
    "for i in new_p:\n",
    "  k = new_p[i]\n",
    "  for j in range(1, int(len(k)/2)+1):\n",
    "    d = new_p[i]['USER_dial'+str(j)].strip()\n",
    "    d = d.replace(\">\", \"\").replace(\"\\n\", \" \")\n",
    "    new_p[i]['USER_dial'+str(j)] = d\n",
    "\n",
    "#new_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f49550f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'USER_dial1': '  As a child i was abused emotionally by my mum, and sometimes by dad . I was groomed by a friend of the family and was sexually abused by him . A few years later i wind up in a relationship of a narcissistic manipulator . My daughter who was preteens by this point, changed.  She became my abuser',\n",
       " 'Model_dial1': 'Verbally, physically and emotionally . She was taken out of my care due to safeguarding my other children, herself and myself .',\n",
       " 'USER_dial2': 'What your son and daughter are doing is wrong and out of order.  Stick up for yourself because this in turn will show them that your not a pushover.  They may well have such thoughts?',\n",
       " 'Model_dial2': ' Yah you are right.  Do i have to strict on them?  Is it right.',\n",
       " 'USER_dial3': 'To controll them and show them right path you have to strict there is nothing wrong in this.  They are your children you know better how to teach them a good lession and bring them back to right path.',\n",
       " 'Model_dial3': ' Thank you for your advice.  it help me a lot.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in new_a:\n",
    "  k = new_a[i]\n",
    "  for j in range(1, int(len(k)/2)+1):\n",
    "    d = new_a[i]['Model_dial'+str(j)].strip()\n",
    "    d = d.replace(\">\", \"\").replace(\"\\n\", \" \")\n",
    "    new_a[i]['Model_dial'+str(j)] = d\n",
    "\n",
    "\n",
    "for i in new_d:\n",
    "  k = new_d[i]\n",
    "  for j in range(1, int(len(k)/2)+1):\n",
    "    d = new_d[i]['Model_dial'+str(j)].strip()\n",
    "    d = d.replace(\">\", \"\").replace(\"\\n\", \" \")\n",
    "    new_d[i]['Model_dial'+str(j)] = d\n",
    "\n",
    "\n",
    "for i in new_o:\n",
    "  k = new_o[i]\n",
    "  for j in range(1, int(len(k)/2)+1):\n",
    "    d = new_o[i]['Model_dial'+str(j)].strip()\n",
    "    d = d.replace(\">\", \"\").replace(\"\\n\", \" \")\n",
    "    new_o[i]['Model_dial'+str(j)] = d\n",
    "\n",
    "\n",
    "for i in new_p:\n",
    "  k = new_p[i]\n",
    "  for j in range(1, int(len(k)/2)+1):\n",
    "    d = new_p[i]['Model_dial'+str(j)].strip()\n",
    "    d = d.replace(\">\", \"\").replace(\"\\n\", \" \")\n",
    "    new_p[i]['Model_dial'+str(j)] = d\n",
    "\n",
    "new_p[65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53920ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_anx_a = new_a\n",
    "out_anx_d = new_d\n",
    "out_anx_o = new_o\n",
    "out_anx_p = new_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4672ef79",
   "metadata": {},
   "source": [
    "Converting to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8221d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7087"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_anx_l = []\n",
    "for i in out_anx_a:\n",
    "  l = len(out_anx_a[i])\n",
    "  a = []\n",
    "  for j in range(1, int(l/2+1)):\n",
    "    a.append(out_anx_a[i]['USER_dial' + str(j)])\n",
    "    a.append(out_anx_a[i]['Model_dial' + str(j)])\n",
    "  out_anx_l.append(a)\n",
    "\n",
    "\n",
    "for i in out_anx_d:\n",
    "  l = len(out_anx_d[i])\n",
    "  a = []\n",
    "  for j in range(1, int(l/2+1)):\n",
    "    a.append(out_anx_d[i]['USER_dial' + str(j)])\n",
    "    a.append(out_anx_d[i]['Model_dial' + str(j)])\n",
    "  out_anx_l.append(a)\n",
    "\n",
    "for i in out_anx_o:\n",
    "  l = len(out_anx_o[i])\n",
    "  a = []\n",
    "  for j in range(1, int(l/2+1)):\n",
    "    a.append(out_anx_o[i]['USER_dial' + str(j)])\n",
    "    a.append(out_anx_o[i]['Model_dial' + str(j)])\n",
    "  out_anx_l.append(a)\n",
    "\n",
    "\n",
    "for i in out_anx_p:\n",
    "  l = len(out_anx_p[i])\n",
    "  a = []\n",
    "  for j in range(1, int(l/2+1)):\n",
    "    a.append(out_anx_p[i]['USER_dial' + str(j)])\n",
    "    a.append(out_anx_p[i]['Model_dial' + str(j)])\n",
    "  out_anx_l.append(a)\n",
    "\n",
    "len(out_anx_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85c5d1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = out_anx_l[0]\n",
    "\n",
    "updated_list = list(filter(None, k))\n",
    "\n",
    "out_anx_l[0] = updated_list\n",
    "#print(updated_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "897afcbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7087"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = out_anx_l\n",
    "\n",
    "len(out_anx_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03adb79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ec5e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in lst:\n",
    "  for j in range(math.ceil(len(i)/2)+1):\n",
    "    if j%2 == 0:\n",
    "      i[j] = \"#Human \" + i[j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee6feb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#Human   i just barly passed my permit test just guessing and logic . i am an okay driver, i drive better when in a bad mood or preoccupied with something its bothering me . My boyfriend left the car and the guy giving memy drivers test came out . He asked me to turn my 4 ways on, wipers, beep horn and so on.  while he asking me this stuff i could only half focus on what he was saying like my ears were hearing but my brain would only proccess half way .',\n",
       " '#Assistant   A panic attack is abrupt and usually occurs out of nowhere, with no apparent trigger . There are different degrees of attacks, some are far worse than others . Some common symptoms include tingling or numbness in hands and/or feet..feeling disconnected or disoriented...shortness of breath, feeling like your choking, shaking, crying, extreme sweating .',\n",
       " '#Human   i only get \"them\" when i am a bad situation like getting a shot, presenting projects and ideas, or having a person conversation with my parents or like anyone i know personally . i have no problem telling my life to people iv only met a few times, but  numb or shaky hands hands depending how well i control myself .',\n",
       " \"#Assistant   It doesn't sound like you had a panic attack, but you certainly sounded very nervous . Fortunately a lot of people get really nervous in situations like yours, so you're definitely not alone . You may want to look into a variety of stress management techniques, or read up on coping with being nervous.\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in lst:\n",
    "  for j in range(math.ceil(len(i)/2)+2):\n",
    "    if j%2 != 0:\n",
    "      i[j] = \"#Assistant \" + i[j]\n",
    "\n",
    "lst[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7601952",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69ab008d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Human   I just need to vent and hopefully get support.  I have an 8 y/o with autism/aspergers.  He is very inquisitive and very \"in his own head\" and doesn\\'t care at all if he is with a group . If he sees something interesting, off he goes #Assistant He\\'s gone in the blink of an eye .'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(lst)):\n",
    "  m = lst[i]\n",
    "  res = \" \".join([str(item) for item in m])\n",
    "  final_list.append(res)\n",
    "\n",
    "final_list[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "721cf89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Human says he\\'s always been anxious when with other people . He\\'s trying just to \"be myself\" using some mindfulness techniques . Breathing, listening to his senses, accepting whatever thoughts and emotions pop up without giving them too much weight . Now he finds himself being more spontanous and managing to get a feeling of belonging without the need to be \"intelligent\" #Assistant  Hello, I hope you will be able to find and feel some connection communicating here.  ACT Therapy is . Do you actually do this with a Therapist? #Human  No, I\\'ve read some books and went to a lecture of a therapist who is using this technique. #Assistant  Hi, Care to mention what the name of the book is? #Human  Hi again, 2 books: A practical guide to acceptance and commitment therapy / edited by Steven Hayes and Kirk D. Strosahl Acceptance and commitment therapy : an experiential approach to behavior change / Steven C. Hayes, Kirk D. Strosahl, Kelly G. Wilson #Assistant   Jon Kabat-Zinn was one of the first people in western medicine to apply mindfulness to stress reduction and anxiety . He developed a program he calls Mindfulness- Based Stress Reduction MBSR . Google his name for lots of videos from him about mindfulness and his research .  Thank, I\\'ll do that.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {}\n",
    "for i in range(len(final_list)):\n",
    "  d[i] = final_list[i]\n",
    "\n",
    "d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a46ea3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(list(d.values()), index=d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4fbccf06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Human says he's always been anxious when with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#Human   i just barly passed my permit test ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Human   My fiance had an emotional affair tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Human   I find it almost impossible to speak ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#Human  AGHH anxiety high today and complicate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Conversation\n",
       "0  #Human says he's always been anxious when with...\n",
       "1  #Human   i just barly passed my permit test ju...\n",
       "2  #Human   My fiance had an emotional affair tha...\n",
       "3  #Human   I find it almost impossible to speak ...\n",
       "4  #Human  AGHH anxiety high today and complicate..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns = ['Conversation']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efad0650",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d7fe77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d047cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = dataset.train_test_split(test_size=0.1, shuffle=True, seed=42)\n",
    "\n",
    "# dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44398810",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = dataset_train['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6e68046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6c8c530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d902aebf53704d799b9ff345d7a0c14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6378 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Conversation', 'text'],\n",
       "    num_rows: 6378\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define a function to transform the data\n",
    "def transform_conversation(example):\n",
    "    conversation_text = example['Conversation']\n",
    "    segments = conversation_text.split('#')\n",
    "\n",
    "    reformatted_segments = []\n",
    "\n",
    "    # Iterate over pairs of segments\n",
    "    for i in range(1, len(segments) - 1, 2):\n",
    "        human_text = segments[i].strip().replace('Human', '').strip()\n",
    "\n",
    "        # Check if there is a corresponding assistant segment before processing\n",
    "        if i + 1 < len(segments):\n",
    "            assistant_text = segments[i+1].strip().replace('Assistant', '').strip()\n",
    "\n",
    "            # Apply the new template\n",
    "            reformatted_segments.append(f'<s>[INST] {human_text} [/INST] {assistant_text} </s>')\n",
    "        else:\n",
    "            # Handle the case where there is no corresponding assistant segment\n",
    "            reformatted_segments.append(f'<s>[INST] {human_text} [/INST] </s>')\n",
    "\n",
    "    return {'text': ''.join(reformatted_segments)}\n",
    "\n",
    "# Apply the transformation\n",
    "transformed_dataset = dataset1.map(transform_conversation)\n",
    "transformed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e82c5eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Conversation', 'text'],\n",
       "    num_rows: 6378\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d45ba524",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset = transformed_dataset.remove_columns(['Conversation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc6ebe67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 6378\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce0336a",
   "metadata": {},
   "source": [
    "ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e42a07b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 #transformers==4.38.2# trl==0.4.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de000233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall -y transformer-engine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff0822f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install trl==0.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "309c87e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,HfArgumentParser,TrainingArguments,pipeline, logging\n",
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
    "import os,torch\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a46bd72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "dataset = transformed_dataset\n",
    "new_model = \"mistral_7b_guanaco_v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db0bdce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a675dc637f24407b5d2e64b3d77fa81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login(\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a9d14870",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:466: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9a94911fb74f55905451baca0d70f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# bnb_config = BitsAndBytesConfig(  \n",
    "#     load_in_4bit= True,\n",
    "#     bnb_4bit_quant_type= \"nf4\",\n",
    "#     bnb_4bit_compute_dtype= torch.float16,\n",
    "#     bnb_4bit_use_double_quant= False,\n",
    "# )\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model,\n",
    "#         load_in_4bit=True,\n",
    "        use_auth_token=\"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\",\n",
    "#         quantization_config=bnb_config,\n",
    "#         torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "#         trust_remote_code=True,\n",
    ")\n",
    "\n",
    "model.config.use_cache = False # silence the warnings\n",
    "model.config.pretraining_tp = 1\n",
    "# model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b60624e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:720: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model, use_auth_token=\"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\", trust_remote_code=True)\n",
    "tokenizer.padding_side = 'right'\n",
    "tokenizer.pad_token = tokenizer.unk_token \n",
    "tokenizer.add_eos_token = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0be1d5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    r=16,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\"]\n",
    ")\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e9ee9b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"./results_v2\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=25,\n",
    "    logging_steps=25,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "#     report_to=\"tensorboard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b1fb39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae0a306ed444a8a95e364de18fc8c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6378 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length= None,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing= False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cfac8b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using 8-bit optimizers with a version of `bitsandbytes` < 0.41.1. It is recommended to update your version as a major bug has been fixed in 8-bit optimizers.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1595' max='1595' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1595/1595 19:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.862500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.579900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>2.564400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.434000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>2.441000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.391600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>2.402700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.426500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>2.473800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.376700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>2.456100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.402000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>2.416900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.361000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>2.407600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.312200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>2.445400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.344700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>2.423900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.357500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>2.422600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.294100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>2.393000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.364400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>2.386200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.419800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>2.456700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.308000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>2.421000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.363200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>2.411500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.392400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>2.361000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.360100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>2.386400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.431700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>2.405300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.396200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>2.391300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.389800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>2.413700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>2.361300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>2.423800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.275700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>2.391000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>2.324300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>2.384500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.347300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>2.393800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>2.373700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>2.449100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.347300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>2.447100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>2.350300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>2.401200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.350200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>2.402700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>2.350300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>2.427900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.328500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525</td>\n",
       "      <td>2.409700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>2.325200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>2.419400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results_v2/checkpoint-25 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-50 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-75 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-100 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-125 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-150 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-175 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-200 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-225 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-250 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-275 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-300 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-325 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-350 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-375 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-400 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-425 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-450 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-475 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-525 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-550 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-575 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-600 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-625 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-650 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-675 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-700 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-725 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-750 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-775 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-800 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-825 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-850 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-875 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-900 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-925 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-950 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-975 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-1025 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-1050 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-1075 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-1100 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-1125 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-1150 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-1175 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-1200 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-1225 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-1250 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-1275 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-1300 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-1325 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-1350 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-1375 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-1400 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-1425 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-1450 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-1475 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-1525 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-1550 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results_v2/checkpoint-1575 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1595, training_loss=2.4008856172471957, metrics={'train_runtime': 1191.1119, 'train_samples_per_second': 5.355, 'train_steps_per_second': 1.339, 'total_flos': 5.831044264658534e+16, 'train_loss': 2.4008856172471957, 'epoch': 1.0})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a020d5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] You are first point contact for mental health support seekers 'I know i have no control, this could have happened to anyone. and when the crisis came i did everything i could. but... i nearly failed, i almost did not make it. and everytime i put my little girl to bed i wonder if this will be the last time i see her. it is just the stupid ptsd, anxiety and depression are having a field day' [/INST] I'm really sorry to hear that you're going through a difficult time right now. It takes a great deal of courage to reach out for support, and I want you to know that you're not alone. I can't imagine how painful it must be to experience intrusive thoughts and feelings, especially when it comes to the safety and well-being of your child.\n",
      "\n",
      "It's important to acknowledge that what you've been through is not your fault, and that having\n"
     ]
    }
   ],
   "source": [
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "prompt = \"You are first point contact for mental health support seekers 'I know i have no control, this could have happened to anyone. and when the crisis came i did everything i could. but... i nearly failed, i almost did not make it. and everytime i put my little girl to bed i wonder if this will be the last time i see her. it is just the stupid ptsd, anxiety and depression are having a field day'\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c7486ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] You are first point contact for mental health support seekers 'In the fall of 2010, i lost a job and my depression became unmanageable. the level of distress i go in and out of now is beyond anything i have ever experienced in past years. iâ€™ve always had social anxiety and depression are partnered up like a tag team holding me down.' [/INST] I'm really sorry to hear that you've been going through a difficult time lately, losing a job and experiencing unmanageable depression and social anxiety. I can only imagine how challenging and overwhelming this must be for you.\n",
      "\n",
      "First and foremost, I want to assure you that you're not alone in this. Many people experience depression and social anxiety, and there are resources and support available to help you manage these feelings.\n",
      "\n",
      "It's important to take care of yourself during this time. This might include things like getting enough sleep,\n"
     ]
    }
   ],
   "source": [
    "prompt = \"You are first point contact for mental health support seekers 'In the fall of 2010, i lost a job and my depression became unmanageable. the level of distress i go in and out of now is beyond anything i have ever experienced in past years. iâ€™ve always had social anxiety and depression are partnered up like a tag team holding me down.'\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6b6f4715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] You are first point contact for mental health support seekers 'I'm wondering how people cope with every day anxiety without panic and without causing extra stress.  I want to just live without having to try to control and have a plan.  I have a planning personality and do this naturally.  But sometimes it just gets overwhelming.' [/INST] I'm glad you've reached out for support with managing everyday anxiety. It's understandable that you're looking for ways to cope without adding extra stress or relying too heavily on planning. Here are some suggestions that might help:\n",
      "\n",
      "1. Mindfulness practices: Mindfulness meditation, deep breathing exercises, and progressive muscle relaxation are all effective ways to reduce anxiety in the moment. These practices can help you focus on the present and bring your attention away from worrying thoughts.\n",
      "2. Physical activity: Regular exercise can help reduce anxiety and improve your overall mood. Aim for at least 30\n"
     ]
    }
   ],
   "source": [
    "prompt = \"You are first point contact for mental health support seekers 'I'm wondering how people cope with every day anxiety without panic and without causing extra stress.  I want to just live without having to try to control and have a plan.  I have a planning personality and do this naturally.  But sometimes it just gets overwhelming.'\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ea4274",
   "metadata": {},
   "source": [
    "EVALUTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824c8196",
   "metadata": {},
   "source": [
    "For BLEUSCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "187e75d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = \"You are first point contact for mental health support seekers 'I have anxiety, my friends and family members don't understand it . I can't help it, but I feel their is something wrong with me . My anxiety makes me feel alone.  It's also though I have no friends to turn to and no one understands what I'm going through.\"\n",
    "\n",
    "prompt2= \"You are first point contact for mental health support seekers 'Lately my ocd like tendencies have been going on a lot more than usual . When they do happen I have no idea what starts it off. Nor do I truly know what to do to make my brain stop obsessing over whatever it is in the moment . And the fact I feel helpless to it seems to side step trigger my depression\"\n",
    "\n",
    "prompt3=\"You are first point contact for mental health support seekers 'Everytime I talk to my mom or just burst out in one of our multiple arguments that I hate my life and want to die, she calls me a drama queen . I just want help, and I'm afraid to ask for it . Does anyone else have parents that don't understand or maybe even care?'\"\n",
    "\n",
    "prompt4= \"You are first point contact for mental health support seekers 'I do not know how much longer I can hold on to the edge...I am slowly slipping away...  I am in a lot of pain today... mental...mental. This sends me into a black abyss... I know my children see me as such a failure' \"\n",
    "\n",
    "prompt5= \"You are first point contact for mental health support seekers 'I appreciate how at least an effort is being made to bring this out in the mainstream where it is brought to light that one's childhood trauma can most definitely create challenges one can struggle with their entire life that can contribute towards affecting their mental and even physical health . However, that being said I do find that having this brought light as though this is entirely new and a revelation does bring me a bit of anger in that this should not be considered 'new' and ground breaking because this has actually been discussed and studied a lot'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a4e45e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [prompt1, prompt2, prompt3,prompt4,prompt5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7ea17913",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for i in p:\n",
    "    k = pipe(f\"<s>[INST] {i} [/INST]\")\n",
    "    pred.append(k[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c10ddc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am so sorry, I hope you are feeling better, Please visit a therapist, May I ask why?, Please consult a psychiatrist., Take care, Hope it helps\n",
    "reference_string = \"I am so sorry, I hope you are feeling better, Please visit a therapist, May I ask why?, Please consult a psychiatrist., Take care, Hope it helps\"\n",
    "r = reference_string.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "33b09c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fdb30ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43812287917486925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "weights = (0.25, 0.25, 0, 0)\n",
    "score = []\n",
    "for i in range(len(pred)):\n",
    "    p = pred[i].split('[/INST]')[1]\n",
    "    s = sentence_bleu(r, p, weights=weights)\n",
    "    score.append(s)\n",
    "    \n",
    "print(np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4195a78d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ca5e890",
   "metadata": {},
   "source": [
    "BERTScore F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d90d6490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4768f08d894949b563e9fa2ffbe9d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore Precision: 0.3402, Recall: 0.5512, F1: 0.4207\n"
     ]
    }
   ],
   "source": [
    "from bert_score import BERTScorer\n",
    "\n",
    "scorer = BERTScorer(model_type='bert-base-uncased')\n",
    "P, R, F1 = scorer.score([p], [r])\n",
    "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dcc8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1c2e97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac69f6a1",
   "metadata": {},
   "source": [
    "PERPLEXITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4d70dee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec0e4928f7c423ba42675bc105aa2f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dataset_train['test']\n",
    "\n",
    "t_dataset = dataset_train['test'].map(transform_conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "79696fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9414de03832b4afeb49a0cead50a6415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "\n",
    "device = \"cuda\"\n",
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id).to(device)\n",
    "tokenizer =  AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "243e1035",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = t_dataset\n",
    "encodings = tokenizer(\"\\n\\n\".join(test[\"text\"]), return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9c5f57aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 317/317 [00:11<00:00, 26.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(190.7325, device='cuda:0')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "max_length = 20\n",
    "stride = 512\n",
    "seq_len = encodings.input_ids.size(1)\n",
    "\n",
    "nlls = []\n",
    "prev_end_loc = 0\n",
    "for begin_loc in tqdm(range(0, seq_len, stride)):\n",
    "    end_loc = min(begin_loc + max_length, seq_len)\n",
    "    trg_len = end_loc - prev_end_loc  # may be different from stride on last loop\n",
    "    input_ids = encodings.input_ids[:, begin_loc:end_loc].to(device)\n",
    "    target_ids = input_ids.clone().to(device)\n",
    "    target_ids[:, :-trg_len] = -100\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=target_ids)\n",
    "\n",
    "        # loss is calculated using CrossEntropyLoss which averages over valid labels\n",
    "        # N.B. the model only calculates loss over trg_len - 1 labels, because it internally shifts the labels\n",
    "        # to the left by 1.\n",
    "        neg_log_likelihood = outputs.loss\n",
    "\n",
    "    nlls.append(neg_log_likelihood)\n",
    "\n",
    "    prev_end_loc = end_loc\n",
    "    if end_loc == seq_len:\n",
    "        break\n",
    "\n",
    "ppl = torch.exp(torch.stack(nlls).mean())\n",
    "ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982b0370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62acbd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
